{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz1PblPcZer6"
      },
      "source": [
        "# Ollama Quickstart\n",
        "\n",
        "In this quickstart you will learn how to use models from Ollama as a feedback function provider.\n",
        "\n",
        "[Ollama](https://ollama.ai/) allows you to get up and running with large language models, locally.\n",
        "\n",
        "Note: you must have installed Ollama to get started with this example.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/examples/expositional/models/local_and_OSS_models/ollama_quickstart.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocJT1ADYZesB"
      },
      "outputs": [],
      "source": [
        "!pip install trulens trulens-apps-langchain trulens-providers-litellm litellm==1.11.1 langchain==0.0.351"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbk2gsjsZesG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uODRM-1iZesG"
      },
      "source": [
        "### Import from LangChain and TruLens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trulens-apps-langchain"
      ],
      "metadata": {
        "id": "H5pCOcH1Z2SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w_P9Iq5kZesH",
        "outputId": "48eddc42-c5a5-4baf-ecc0-06bb994e98be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
            "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_id in records table: 0it [00:00, ?it/s]\n",
            "Updating app_json in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
            "Updating app_id in records table: 0it [00:00, ?it/s]\n",
            "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Imports main tools:\n",
        "# Imports from langchain to build app. You may need to install langchain first\n",
        "# with the following:\n",
        "# !pip install langchain>=0.0.170\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
        "from trulens.core import Feedback\n",
        "from trulens.core import TruSession\n",
        "from trulens.apps.langchain import TruChain\n",
        "\n",
        "session = TruSession()\n",
        "session.reset_database()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWidwtxYZesH"
      },
      "source": [
        "### Let's first just test out a direct call to Ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "L9Ulw0KHaazN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1T7QcxSZesI"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import Ollama\n",
        "\n",
        "ollama = Ollama(base_url=\"http://vpn.jxit.net.cn:11434\", model=\"qwq:latest\")\n",
        "print(ollama(\"why is the sky blue\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMiMPd_OZesI"
      },
      "source": [
        "### Create Simple LLM Application\n",
        "\n",
        "This example uses a LangChain framework and Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LyjTpyQGZesJ",
        "outputId": "5cddf8c5-cdc5-4176-d0ed-cbc2757e9c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-35994de8e82c>:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=ollama, prompt=chat_prompt_template, verbose=True)\n"
          ]
        }
      ],
      "source": [
        "full_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=\"Provide a helpful response with relevant background information for the following: {prompt}\",\n",
        "        input_variables=[\"prompt\"],\n",
        "    )\n",
        ")\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([full_prompt])\n",
        "\n",
        "chain = LLMChain(llm=ollama, prompt=chat_prompt_template, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHzBohBxZesK"
      },
      "source": [
        "### Send your first request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YM23w_bhZesK"
      },
      "outputs": [],
      "source": [
        "prompt_input = \"What is a good name for a store that sells colorful socks?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6z8v8ZuZesK"
      },
      "outputs": [],
      "source": [
        "llm_response = chain(prompt_input)\n",
        "\n",
        "display(llm_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCTMHQNJZesL"
      },
      "source": [
        "## Initialize Feedback Function(s)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm\n",
        "!pip install trulens-eval\n",
        "!pip install trulens-providers-litellm"
      ],
      "metadata": {
        "id": "BiBZlEWObh3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "id": "iUVaX6u2iLqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import Popen\n",
        "from time import sleep\n",
        "# Pulls model from Ollama. Will be used as evaluating llm and generating llm\n",
        "p = Popen([\"ollama\", \"serve\"])  # something long running\n",
        "sleep(1)\n",
        "os.system(f'ollama run llama2')"
      ],
      "metadata": {
        "id": "jTOmJQ_dnvNs",
        "outputId": "47c6447b-ea9b-4c2a-a3dc-4d4af074d37b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "K733I1xXZesL",
        "outputId": "5530bacd-3d5b-475d-cfe4-24ea9781ec7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:18:07 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:18:09 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:18:13 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:18:21 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Endpoint LiteLLMEndpoint request failed 4 time(s): \n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-5da1d137382e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m ollama_provider.relevance_with_cot_reasons(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"What is a good name for a store that sells colorful socks?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"Great question! Naming a store that sells colorful socks can be a fun and creative process. Here are some suggestions to consider: SoleMates: This name plays on the idea of socks being your soul mate or partner in crime for the day. It is catchy and easy to remember, and it conveys the idea that the store offers a wide variety of sock styles and colors.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/feedback/llm_provider.py\u001b[0m in \u001b[0;36mrelevance_with_cot_reasons\u001b[0;34m(self, prompt, response, criteria, examples, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;34m\"RELEVANCE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOT_REASONS_TEMPLATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         )\n\u001b[0;32m--> 514\u001b[0;31m         return self.generate_score_and_reasons(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0msystem_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0muser_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/feedback/llm_provider.py\u001b[0m in \u001b[0;36mgenerate_score_and_reasons\u001b[0;34m(self, system_prompt, user_prompt, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mllm_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response = self.endpoint.run_in_pace(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_completion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/core/feedback/endpoint.py\u001b[0m in \u001b[0;36mrun_in_pace\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mretry_delay\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;34mf\"Endpoint {self.name} request failed {attempts} time(s): \\n\\t\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Endpoint LiteLLMEndpoint request failed 4 time(s): \n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}"
          ]
        }
      ],
      "source": [
        "# Initialize LiteLLM-based feedback function collection class:\n",
        "import litellm\n",
        "import trulens\n",
        "from trulens.providers.litellm import LiteLLM\n",
        "\n",
        "litellm.set_verbose = True\n",
        "\n",
        "ollama_provider = LiteLLM(\n",
        "    model_engine=\"ollama/llama2\", api_base=\"http://vpn.jxit.net.cn:11434\"\n",
        ")\n",
        "\n",
        "ollama_provider.relevance_with_cot_reasons(\n",
        "    \"What is a good name for a store that sells colorful socks?\",\n",
        "    \"Great question! Naming a store that sells colorful socks can be a fun and creative process. Here are some suggestions to consider: SoleMates: This name plays on the idea of socks being your soul mate or partner in crime for the day. It is catchy and easy to remember, and it conveys the idea that the store offers a wide variety of sock styles and colors.\",\n",
        ")\n",
        "\n",
        "# Define a relevance function using LiteLLM\n",
        "relevance = Feedback(\n",
        "    ollama_provider.relevance_with_cot_reasons\n",
        ").on_input_output()\n",
        "# By default this will check relevance on the main app input and main app\n",
        "# output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "p1XQymKaZesL",
        "outputId": "80c06f28-5aa3-48ca-c409-dfa5b51d5ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:17:19 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:17:21 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:17:25 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92m13:17:33 - LiteLLM:WARNING\u001b[0m: utils.py:476 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
            "WARNI [LiteLLM] `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
            "Final returned optional params: {'temperature': 0.0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Endpoint LiteLLMEndpoint request failed 4 time(s): \n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-0ecba057aece>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ollama_provider.relevance_with_cot_reasons(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"What is a good name for a store that sells colorful socks?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Great question! Naming a store that sells colorful socks can be a fun and creative process. Here are some suggestions to consider: SoleMates: This name plays on the idea of socks being your soul mate or partner in crime for the day. It is catchy and easy to remember, and it conveys the idea that the store offers a wide variety of sock styles and colors.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/feedback/llm_provider.py\u001b[0m in \u001b[0;36mrelevance_with_cot_reasons\u001b[0;34m(self, prompt, response, criteria, examples, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;34m\"RELEVANCE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_prompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOT_REASONS_TEMPLATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         )\n\u001b[0;32m--> 514\u001b[0;31m         return self.generate_score_and_reasons(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0msystem_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0muser_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/feedback/llm_provider.py\u001b[0m in \u001b[0;36mgenerate_score_and_reasons\u001b[0;34m(self, system_prompt, user_prompt, min_score_val, max_score_val, temperature)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_prompt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mllm_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response = self.endpoint.run_in_pace(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_completion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trulens/core/feedback/endpoint.py\u001b[0m in \u001b[0;36mrun_in_pace\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mretry_delay\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0;34mf\"Endpoint {self.name} request failed {attempts} time(s): \\n\\t\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Endpoint LiteLLMEndpoint request failed 4 time(s): \n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}\n\tlitellm.BadRequestError: Invalid Message passed in {'role': 'system', 'content': \"You are a RELEVANCE grader; providing the relevance of the given RESPONSE to the given PROMPT.\\nRespond only as a number from 0 to 3, where 0 is the lowest score according to the criteria and 3 is the highest possible score.\\n\\nCriteria for evaluating relevance:\\n\\n        - RESPONSE must be relevant to the entire PROMPT to get a maximum score of 3.\\n        - RELEVANCE score should increase as the RESPONSE provides RELEVANT context to more parts of the PROMPT.\\n        - RESPONSE that is RELEVANT to none of the PROMPT should get a minimum score of 0.\\n        - RESPONSE that is RELEVANT and answers the entire PROMPT completely should get a score of 3.\\n        - RESPONSE that confidently FALSE should get a score of 0.\\n        - RESPONSE that is only seemingly RELEVANT should get a score of 0.\\n        - Answers that intentionally do not answer the question, such as 'I don't know' and model refusals, should also be counted as the least RELEVANT and get a score of 0.\\n    \\n\\nA few additional scoring guidelines:\\n\\n- Long RESPONSES should score equally well as short RESPONSES.\\n\\n- Never elaborate.\"}"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhWkrtbZesL"
      },
      "source": [
        "## Instrument chain for logging with TruLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoIPxc3rZesM"
      },
      "outputs": [],
      "source": [
        "tru_recorder = TruChain(\n",
        "    chain, app_name=\"Chain1_ChatApplication\", feedbacks=[relevance]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6aFOE42ZesM"
      },
      "outputs": [],
      "source": [
        "with tru_recorder as recording:\n",
        "    llm_response = chain(prompt_input)\n",
        "\n",
        "display(llm_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "xc-Zzi06ZesM",
        "outputId": "2607411f-f4a0-4a68-b6f6-a46c0a010fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      app_id  \\\n",
              "0  app_hash_21a017db3a6de5923b722e0525fde47e   \n",
              "\n",
              "                                            app_json  \\\n",
              "0  {'tru_class_info': {'name': 'TruChain', 'modul...   \n",
              "\n",
              "                             type  \\\n",
              "0  LLMChain(langchain.chains.llm)   \n",
              "\n",
              "                                      record_id  \\\n",
              "0  record_hash_7f959fde0f19f846e9484de50e19be0b   \n",
              "\n",
              "                                               input  \\\n",
              "0  What is a good name for a store that sells col...   \n",
              "\n",
              "                                              output tags  \\\n",
              "0  <think>\\n\\nOkay, so I need to come up with a g...    -   \n",
              "\n",
              "                                         record_json  \\\n",
              "0  {'record_id': 'record_hash_7f959fde0f19f846e94...   \n",
              "\n",
              "                                           cost_json  \\\n",
              "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "\n",
              "                                           perf_json  \\\n",
              "0  {\"start_time\": \"2025-03-13T12:33:12.912253\", \"...   \n",
              "\n",
              "                           ts                app_name app_version    latency  \\\n",
              "0  2025-03-13T12:34:45.986705  Chain1_ChatApplication        base  93.074226   \n",
              "\n",
              "   total_tokens  total_cost cost_currency  \n",
              "0             0         0.0           USD  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-003042bc-fad1-4001-87a4-cf8ee5bcd708\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_json</th>\n",
              "      <th>type</th>\n",
              "      <th>record_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>tags</th>\n",
              "      <th>record_json</th>\n",
              "      <th>cost_json</th>\n",
              "      <th>perf_json</th>\n",
              "      <th>ts</th>\n",
              "      <th>app_name</th>\n",
              "      <th>app_version</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>cost_currency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>app_hash_21a017db3a6de5923b722e0525fde47e</td>\n",
              "      <td>{'tru_class_info': {'name': 'TruChain', 'modul...</td>\n",
              "      <td>LLMChain(langchain.chains.llm)</td>\n",
              "      <td>record_hash_7f959fde0f19f846e9484de50e19be0b</td>\n",
              "      <td>What is a good name for a store that sells col...</td>\n",
              "      <td>&lt;think&gt;\\n\\nOkay, so I need to come up with a g...</td>\n",
              "      <td>-</td>\n",
              "      <td>{'record_id': 'record_hash_7f959fde0f19f846e94...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2025-03-13T12:33:12.912253\", \"...</td>\n",
              "      <td>2025-03-13T12:34:45.986705</td>\n",
              "      <td>Chain1_ChatApplication</td>\n",
              "      <td>base</td>\n",
              "      <td>93.074226</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>USD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-003042bc-fad1-4001-87a4-cf8ee5bcd708')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-003042bc-fad1-4001-87a4-cf8ee5bcd708 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-003042bc-fad1-4001-87a4-cf8ee5bcd708');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"session\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"app_hash_21a017db3a6de5923b722e0525fde47e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_json\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LLMChain(langchain.chains.llm)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"record_hash_7f959fde0f19f846e9484de50e19be0b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"What is a good name for a store that sells colorful socks?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<think>\\n\\nOkay, so I need to come up with a good name for a store that sells colorful socks. Let me start by thinking about what aspects are important here. The key points are \\\"colorful\\\" and \\\"socks\\\". Maybe the name should reflect both the variety of colors and the fact that they're selling socks.\\n\\nFirst, I'll brainstorm some ideas. Words related to color could be rainbow, hues, vibrant, kaleidoscope, spectrum, or even more playful terms like splash or vibe. For socks, maybe using words like sox, steps, toes, or something rhyming with sock. Combining these might work.\\n\\nI should consider the tone too. The store probably wants to appeal to a fun and lively audience, so the name shouldn't be too serious. Maybe alliteration could help make it catchy. Let me think of some combinations:\\n\\n- Rainbow Sox: That's straightforward but maybe a bit generic.\\n- Hue Haven: Combines color (hue) with a place (haven), suggesting a destination for colorful socks.\\n- Socktopus: A play on \\\"octopus\\\" since they have eight legs, which could relate to multiple colors? Maybe not the clearest connection.\\n- Zing Socks: \\\"Zing\\\" implies energy and colorfulness. It's catchy but might be too vague.\\n- Color Crew: Suggests a group of colorful socks or a community around colorful fashion. That's good.\\n- Step in Style: Focuses on style, maybe not as directly about colors.\\n- Toe the Line: A phrase that usually means following rules, which might have an unintended meaning here.\\n\\nWait, maybe \\\"Kaleido Sox\\\" since kaleidoscopes are colorful and ever-changing. Or \\\"Vivid Socks\\\" straight up? Hmm. Need something more creative perhaps.\\n\\nAnother angle is to use a pun or a clever twist on common phrases. Like \\\"Socktastic\\\" (a play on \\\"fantastic\\\") which sounds fun. Or \\\"Sockstars\\\" implying they're the stars of your outfit. \\n\\nAlso, thinking about domain names and availability. The name needs to be available as a web address and not trademarked already. But since this is just brainstorming, I can suggest ideas without checking.\\n\\nMaybe combining color terms with sock-related words: Chroma Sox (chroma relates to color), or \\\"Socksational\\\" blending socks and sensational. \\n\\nI should also consider the target audience. If it's for kids, maybe something more playful like \\\"Crazy Colors Crew Socks\\\". For a broader audience, perhaps \\\"Hue & Heel\\\" \\u2013 using heel from sock anatomy and hue for color.\\n\\nWait another thought: \\\"Soleful Colors\\\"? Playing on \\\"sole\\\" (as in shoe sole) but also sounding like soul. Hmm, maybe too obscure. \\n\\nOr \\\"Dye-licious Socks\\\" \\u2013 since socks can be dyed colorful. But Dye-licious might not immediately connect to the product.\\n\\nAnother approach: Using a verb related to color and sock action. Like \\\"SplashStep Sox\\\" where splash implies color splashing on your steps (walking). \\n\\nOr \\\"Vibrant Toes\\\" emphasizing the toes part of socks and vibrant colors. That's direct but maybe too simple.\\n\\nHmm, perhaps \\\"ChromaFit\\\"? Combining chroma with fitness? Not sure if that fits.\\n\\nWait, maybe \\\"The Sock Spectrum\\\" \\u2013 spectrum relates to a range of colors. But Spectrum is a common term, so might be taken.\\n\\nAlternatively, \\\"Hue Horizons\\\" suggesting endless colorful options. \\n\\nI need to think of names that are catchy and easy to remember. Maybe alliteration helps here: \\\"Sassy Sox\\\", \\\"Colorful Crew Socks\\\".\\n\\nWait, going back to the initial examples I thought of:\\n\\n- Color Crew Socks\\n- Hue Haven\\n- Kaleido Sox\\n\\nThese seem solid. Let me check if they make sense. \\n\\n\\\"Color Crew\\\" suggests a team or group of colorful socks, which is friendly and approachable. \\\"Hue Haven\\\" gives a sense of a place where all hues are gathered. \\\"Kaleido Sox\\\" uses the visual aspect of kaleidoscope colors.\\n\\nAnother angle: Using words that suggest variety like \\\"Mix & Match Socks\\\", but maybe not as focused on color.\\n\\nAlternatively, \\\"Vivid Vibes Socks\\\" \\u2013 vibrant energy and colors.\\n\\nHmm, maybe \\\"Socks Alive!\\\" playing on the idea of colorful socks making your feet pop. \\n\\nOr \\\"Step in Hue\\\" combining stepping (as in walking) with hue for color.\\n\\nI think I have a few options here. The user probably wants a list with explanations so they can choose. Need to present them clearly, maybe 10 ideas with brief rationales.\\n</think>\\n\\nHere\\u2019s a curated list of creative and catchy names for a store selling colorful socks, along with their meanings and rationale:\\n\\n---\\n\\n### **Top Name Suggestions**\\n1. **Hue Haven**  \\n   - Combines *hue* (color) with *haven* (a welcoming place), creating an inviting destination for vibrant sock lovers.\\n\\n2. **Kaleido Sox**  \\n   - *Kaleidoscope* evokes a mix of colors, while *Sox* is a playful twist on \\\"socks,\\\" suggesting endless colorful patterns.\\n\\n3. **Vivid Vibes Socks**  \\n   - Emphasizes energy (*vibes*) and boldness (*vivid*), appealing to customers seeking stylish, eye-catching socks.\\n\\n4. **Color Crew**  \\n   - A friendly, approachable name that positions the store as a \\\"team\\\" of colorful socks ready to elevate any outfit.\\n\\n5. **Soleful Colors**  \\n   - *Soul* and *sole* (the bottom of your foot) blend with *colors*, creating a punny nod to both style and comfort.\\n\\n6. **Zing Socks Co.**  \\n   - *Zing* implies liveliness and brightness, making the brand feel dynamic and fun for all ages.\\n\\n7. **Rainbow Steps**  \\n   - Highlights playful color variety (*rainbow*) while subtly referencing movement (*steps*), perfect for a lively vibe.\\n\\n8. **Socksational**  \\n   - A blend of *socks* and *spectacular*, making the name catchy and memorable for its alliteration and energy.\\n\\n9. **Dye-licious Socks**  \\n   - Playful use of *dye* (as in sock coloring) paired with *delicious*, evoking excitement about bold hues.\\n\\n10. **Toe the Hue Line**  \\n    - A pun on \\\"toe the line\\\" (a common phrase meaning strict adherence), subverted here to mean embracing colorful creativity.\\n\\n---\\n\\n### **Key Considerations**\\n- **Tone**: Names like *Color Crew* or *Vivid Vibes* emphasize fun and approachability, while others (*Hue Haven*) feel more curated.  \\n- **Memorability**: Alliteration (*Socksational*, *Kaleido Sox*) and wordplay (*Dye-licious*) help brands stick in customers\\u2019 minds.  \\n- **Brand Identity**: If targeting a younger crowd, playful names like *Zing Socks* work well; for a broader audience, *Hue Haven* balances creativity with simplicity.\\n\\n---\\n\\n### **Final Tips**\\n- **Check Availability**: Ensure the name is available as a domain and not trademarked before finalizing.  \\n- **Visualize It**: Pair the name with vibrant branding elements (e.g., rainbow logos) to reinforce its colorful theme.  \\n\\nThese names blend creativity, clarity, and personality\\u2014key traits for standing out in the sock market! \\ud83e\\udde6\\ud83c\\udf08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_json\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cost_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"n_requests\\\": 0, \\\"n_successful_requests\\\": 0, \\\"n_completion_requests\\\": 0, \\\"n_classification_requests\\\": 0, \\\"n_classes\\\": 0, \\\"n_embedding_requests\\\": 0, \\\"n_embeddings\\\": 0, \\\"n_tokens\\\": 0, \\\"n_stream_chunks\\\": 0, \\\"n_prompt_tokens\\\": 0, \\\"n_completion_tokens\\\": 0, \\\"n_cortex_guardrails_tokens\\\": 0, \\\"cost\\\": 0.0, \\\"cost_currency\\\": \\\"USD\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perf_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"start_time\\\": \\\"2025-03-13T12:33:12.912253\\\", \\\"end_time\\\": \\\"2025-03-13T12:34:45.986479\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-03-13T12:34:45.986705\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Chain1_ChatApplication\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 93.074226,\n        \"max\": 93.074226,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          93.074226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cost_currency\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"USD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "session.get_records_and_feedback()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb6eeUoSZesM"
      },
      "source": [
        "## Explore in a Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nKiY8JcPZesN",
        "outputId": "d84cef1b-6daa-4a57-aa13-1f4d9018a20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dashboard ...\n",
            "npm warn exec The following package was not found and will be installed: localtunnel@2.0.2\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://pink-goats-speak.loca.lt\n",
            "\n",
            "  Submit this IP Address: 34.106.255.215\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "from trulens.dashboard import run_dashboard\n",
        "\n",
        "run_dashboard(session)  # open a local streamlit app to explore\n",
        "\n",
        "# stop_dashboard(session) # stop if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApP-M2nZesN"
      },
      "source": [
        "## Or view results directly in your notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3BetAFFVZesN",
        "outputId": "6fa0526f-06a4-462b-9179-0060c47e18a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      app_id  \\\n",
              "0  app_hash_21a017db3a6de5923b722e0525fde47e   \n",
              "\n",
              "                                            app_json  \\\n",
              "0  {'tru_class_info': {'name': 'TruChain', 'modul...   \n",
              "\n",
              "                             type  \\\n",
              "0  LLMChain(langchain.chains.llm)   \n",
              "\n",
              "                                      record_id  \\\n",
              "0  record_hash_7f959fde0f19f846e9484de50e19be0b   \n",
              "\n",
              "                                               input  \\\n",
              "0  What is a good name for a store that sells col...   \n",
              "\n",
              "                                              output tags  \\\n",
              "0  <think>\\n\\nOkay, so I need to come up with a g...    -   \n",
              "\n",
              "                                         record_json  \\\n",
              "0  {'record_id': 'record_hash_7f959fde0f19f846e94...   \n",
              "\n",
              "                                           cost_json  \\\n",
              "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
              "\n",
              "                                           perf_json  \\\n",
              "0  {\"start_time\": \"2025-03-13T12:33:12.912253\", \"...   \n",
              "\n",
              "                           ts relevance_with_cot_reasons_calls  \\\n",
              "0  2025-03-13T12:34:45.986705                               []   \n",
              "\n",
              "   relevance_with_cot_reasons feedback cost in USD                app_name  \\\n",
              "0                                              0.0  Chain1_ChatApplication   \n",
              "\n",
              "  app_version    latency  total_tokens  total_cost cost_currency  \n",
              "0        base  93.074226             0         0.0           USD  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd87f92-cdf1-43de-af71-4f1eb693445f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>app_json</th>\n",
              "      <th>type</th>\n",
              "      <th>record_id</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>tags</th>\n",
              "      <th>record_json</th>\n",
              "      <th>cost_json</th>\n",
              "      <th>perf_json</th>\n",
              "      <th>ts</th>\n",
              "      <th>relevance_with_cot_reasons_calls</th>\n",
              "      <th>relevance_with_cot_reasons feedback cost in USD</th>\n",
              "      <th>app_name</th>\n",
              "      <th>app_version</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_tokens</th>\n",
              "      <th>total_cost</th>\n",
              "      <th>cost_currency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>app_hash_21a017db3a6de5923b722e0525fde47e</td>\n",
              "      <td>{'tru_class_info': {'name': 'TruChain', 'modul...</td>\n",
              "      <td>LLMChain(langchain.chains.llm)</td>\n",
              "      <td>record_hash_7f959fde0f19f846e9484de50e19be0b</td>\n",
              "      <td>What is a good name for a store that sells col...</td>\n",
              "      <td>&lt;think&gt;\\n\\nOkay, so I need to come up with a g...</td>\n",
              "      <td>-</td>\n",
              "      <td>{'record_id': 'record_hash_7f959fde0f19f846e94...</td>\n",
              "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
              "      <td>{\"start_time\": \"2025-03-13T12:33:12.912253\", \"...</td>\n",
              "      <td>2025-03-13T12:34:45.986705</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Chain1_ChatApplication</td>\n",
              "      <td>base</td>\n",
              "      <td>93.074226</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>USD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd87f92-cdf1-43de-af71-4f1eb693445f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cd87f92-cdf1-43de-af71-4f1eb693445f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cd87f92-cdf1-43de-af71-4f1eb693445f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"session\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"app_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"app_hash_21a017db3a6de5923b722e0525fde47e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_json\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LLMChain(langchain.chains.llm)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"record_hash_7f959fde0f19f846e9484de50e19be0b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"What is a good name for a store that sells colorful socks?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"<think>\\n\\nOkay, so I need to come up with a good name for a store that sells colorful socks. Let me start by thinking about what aspects are important here. The key points are \\\"colorful\\\" and \\\"socks\\\". Maybe the name should reflect both the variety of colors and the fact that they're selling socks.\\n\\nFirst, I'll brainstorm some ideas. Words related to color could be rainbow, hues, vibrant, kaleidoscope, spectrum, or even more playful terms like splash or vibe. For socks, maybe using words like sox, steps, toes, or something rhyming with sock. Combining these might work.\\n\\nI should consider the tone too. The store probably wants to appeal to a fun and lively audience, so the name shouldn't be too serious. Maybe alliteration could help make it catchy. Let me think of some combinations:\\n\\n- Rainbow Sox: That's straightforward but maybe a bit generic.\\n- Hue Haven: Combines color (hue) with a place (haven), suggesting a destination for colorful socks.\\n- Socktopus: A play on \\\"octopus\\\" since they have eight legs, which could relate to multiple colors? Maybe not the clearest connection.\\n- Zing Socks: \\\"Zing\\\" implies energy and colorfulness. It's catchy but might be too vague.\\n- Color Crew: Suggests a group of colorful socks or a community around colorful fashion. That's good.\\n- Step in Style: Focuses on style, maybe not as directly about colors.\\n- Toe the Line: A phrase that usually means following rules, which might have an unintended meaning here.\\n\\nWait, maybe \\\"Kaleido Sox\\\" since kaleidoscopes are colorful and ever-changing. Or \\\"Vivid Socks\\\" straight up? Hmm. Need something more creative perhaps.\\n\\nAnother angle is to use a pun or a clever twist on common phrases. Like \\\"Socktastic\\\" (a play on \\\"fantastic\\\") which sounds fun. Or \\\"Sockstars\\\" implying they're the stars of your outfit. \\n\\nAlso, thinking about domain names and availability. The name needs to be available as a web address and not trademarked already. But since this is just brainstorming, I can suggest ideas without checking.\\n\\nMaybe combining color terms with sock-related words: Chroma Sox (chroma relates to color), or \\\"Socksational\\\" blending socks and sensational. \\n\\nI should also consider the target audience. If it's for kids, maybe something more playful like \\\"Crazy Colors Crew Socks\\\". For a broader audience, perhaps \\\"Hue & Heel\\\" \\u2013 using heel from sock anatomy and hue for color.\\n\\nWait another thought: \\\"Soleful Colors\\\"? Playing on \\\"sole\\\" (as in shoe sole) but also sounding like soul. Hmm, maybe too obscure. \\n\\nOr \\\"Dye-licious Socks\\\" \\u2013 since socks can be dyed colorful. But Dye-licious might not immediately connect to the product.\\n\\nAnother approach: Using a verb related to color and sock action. Like \\\"SplashStep Sox\\\" where splash implies color splashing on your steps (walking). \\n\\nOr \\\"Vibrant Toes\\\" emphasizing the toes part of socks and vibrant colors. That's direct but maybe too simple.\\n\\nHmm, perhaps \\\"ChromaFit\\\"? Combining chroma with fitness? Not sure if that fits.\\n\\nWait, maybe \\\"The Sock Spectrum\\\" \\u2013 spectrum relates to a range of colors. But Spectrum is a common term, so might be taken.\\n\\nAlternatively, \\\"Hue Horizons\\\" suggesting endless colorful options. \\n\\nI need to think of names that are catchy and easy to remember. Maybe alliteration helps here: \\\"Sassy Sox\\\", \\\"Colorful Crew Socks\\\".\\n\\nWait, going back to the initial examples I thought of:\\n\\n- Color Crew Socks\\n- Hue Haven\\n- Kaleido Sox\\n\\nThese seem solid. Let me check if they make sense. \\n\\n\\\"Color Crew\\\" suggests a team or group of colorful socks, which is friendly and approachable. \\\"Hue Haven\\\" gives a sense of a place where all hues are gathered. \\\"Kaleido Sox\\\" uses the visual aspect of kaleidoscope colors.\\n\\nAnother angle: Using words that suggest variety like \\\"Mix & Match Socks\\\", but maybe not as focused on color.\\n\\nAlternatively, \\\"Vivid Vibes Socks\\\" \\u2013 vibrant energy and colors.\\n\\nHmm, maybe \\\"Socks Alive!\\\" playing on the idea of colorful socks making your feet pop. \\n\\nOr \\\"Step in Hue\\\" combining stepping (as in walking) with hue for color.\\n\\nI think I have a few options here. The user probably wants a list with explanations so they can choose. Need to present them clearly, maybe 10 ideas with brief rationales.\\n</think>\\n\\nHere\\u2019s a curated list of creative and catchy names for a store selling colorful socks, along with their meanings and rationale:\\n\\n---\\n\\n### **Top Name Suggestions**\\n1. **Hue Haven**  \\n   - Combines *hue* (color) with *haven* (a welcoming place), creating an inviting destination for vibrant sock lovers.\\n\\n2. **Kaleido Sox**  \\n   - *Kaleidoscope* evokes a mix of colors, while *Sox* is a playful twist on \\\"socks,\\\" suggesting endless colorful patterns.\\n\\n3. **Vivid Vibes Socks**  \\n   - Emphasizes energy (*vibes*) and boldness (*vivid*), appealing to customers seeking stylish, eye-catching socks.\\n\\n4. **Color Crew**  \\n   - A friendly, approachable name that positions the store as a \\\"team\\\" of colorful socks ready to elevate any outfit.\\n\\n5. **Soleful Colors**  \\n   - *Soul* and *sole* (the bottom of your foot) blend with *colors*, creating a punny nod to both style and comfort.\\n\\n6. **Zing Socks Co.**  \\n   - *Zing* implies liveliness and brightness, making the brand feel dynamic and fun for all ages.\\n\\n7. **Rainbow Steps**  \\n   - Highlights playful color variety (*rainbow*) while subtly referencing movement (*steps*), perfect for a lively vibe.\\n\\n8. **Socksational**  \\n   - A blend of *socks* and *spectacular*, making the name catchy and memorable for its alliteration and energy.\\n\\n9. **Dye-licious Socks**  \\n   - Playful use of *dye* (as in sock coloring) paired with *delicious*, evoking excitement about bold hues.\\n\\n10. **Toe the Hue Line**  \\n    - A pun on \\\"toe the line\\\" (a common phrase meaning strict adherence), subverted here to mean embracing colorful creativity.\\n\\n---\\n\\n### **Key Considerations**\\n- **Tone**: Names like *Color Crew* or *Vivid Vibes* emphasize fun and approachability, while others (*Hue Haven*) feel more curated.  \\n- **Memorability**: Alliteration (*Socksational*, *Kaleido Sox*) and wordplay (*Dye-licious*) help brands stick in customers\\u2019 minds.  \\n- **Brand Identity**: If targeting a younger crowd, playful names like *Zing Socks* work well; for a broader audience, *Hue Haven* balances creativity with simplicity.\\n\\n---\\n\\n### **Final Tips**\\n- **Check Availability**: Ensure the name is available as a domain and not trademarked before finalizing.  \\n- **Visualize It**: Pair the name with vibrant branding elements (e.g., rainbow logos) to reinforce its colorful theme.  \\n\\nThese names blend creativity, clarity, and personality\\u2014key traits for standing out in the sock market! \\ud83e\\udde6\\ud83c\\udf08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"record_json\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cost_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"n_requests\\\": 0, \\\"n_successful_requests\\\": 0, \\\"n_completion_requests\\\": 0, \\\"n_classification_requests\\\": 0, \\\"n_classes\\\": 0, \\\"n_embedding_requests\\\": 0, \\\"n_embeddings\\\": 0, \\\"n_tokens\\\": 0, \\\"n_stream_chunks\\\": 0, \\\"n_prompt_tokens\\\": 0, \\\"n_completion_tokens\\\": 0, \\\"n_cortex_guardrails_tokens\\\": 0, \\\"cost\\\": 0.0, \\\"cost_currency\\\": \\\"USD\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perf_json\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"start_time\\\": \\\"2025-03-13T12:33:12.912253\\\", \\\"end_time\\\": \\\"2025-03-13T12:34:45.986479\\\"}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-03-13T12:34:45.986705\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_with_cot_reasons_calls\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevance_with_cot_reasons feedback cost in USD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Chain1_ChatApplication\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"app_version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 93.074226,\n        \"max\": 93.074226,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          93.074226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_cost\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cost_currency\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"USD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "session.get_records_and_feedback()[0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "vscode": {
      "interpreter": {
        "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}